{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这是基于`Matrix Factorization`的加入正则项的普通 \\( MSE \\)的协同过滤算法来进行的书籍评分的预测，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库\n",
    "import torch \n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#sklearn库\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User     Book  Rate                       Time         Tag\n",
      "0       1398478  1467022     0  2011-03-29T12:48:35+08:00         NaN\n",
      "1       1398478  1777823     0  2011-02-02T21:58:55+08:00         NaN\n",
      "2       1398478  1902628     0  2011-01-31T15:57:58+08:00         NaN\n",
      "3       1398478  1878708     0  2011-01-26T11:27:59+08:00         NaN\n",
      "4       1398478  4238362     0  2011-01-21T13:04:15+08:00         NaN\n",
      "...         ...      ...   ...                        ...         ...\n",
      "637249  4507957  1125186     4  2009-07-04T08:02:13+08:00  张爱玲,半生缘,爱情\n",
      "637250  4507957  1002299     5  2009-07-04T08:01:28+08:00  金庸,武侠,笑傲江湖\n",
      "637251  4507957  1001136     4  2009-07-04T07:55:17+08:00     彼得・潘,童话\n",
      "637252  4507957  1021615     5  2009-07-04T07:53:54+08:00   小王子,童话,经典\n",
      "637253  4507957  1962929     5  2009-06-29T22:13:37+08:00          爱情\n",
      "\n",
      "[637254 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#读取book_score_csv\n",
    "file_path = ('data/book_score.csv')\n",
    "read_data = pd.read_csv(file_path)\n",
    "print(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#用户和书籍的个数，构建 P Q 矩阵需要\n",
    "users_nums = len(read_data['User'].unique())\n",
    "books_nums = len(read_data['Book'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己的书籍评分数据集类，返回用户 id的index ，书籍 id的index , 以及对应的评分\n",
    "class BookScoreDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, read_data, all_dataset = None):\n",
    "        self.read_data = read_data\n",
    "        if all_dataset == None:\n",
    "            #依据字典索引得到 user 和 book 的 id 列表\n",
    "            self.users_unique_id_list = read_data['User'].unique()\n",
    "            self.books_unique_id_list = read_data['Book'].unique()\n",
    "            self.users_unique_id_list = sorted(set(self.users_unique_id_list))\n",
    "            self.books_unique_id_list = sorted(set(self.books_unique_id_list))\n",
    "            #依据id列表，创建 user 和 book 的分别从 id 到 index 的转换，便于实现利用索引访问对应的矩阵 factor\n",
    "            self.user_id_to_index = {id : index for index, id in enumerate(self.users_unique_id_list)}\n",
    "            self.book_id_to_index = {id : index for index, id in enumerate(self.books_unique_id_list)}\n",
    "        else:\n",
    "            self.user_id_to_index = all_dataset.user_id_to_index\n",
    "            self.book_id_to_index = all_dataset.book_id_to_index\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # 得到数据文件中index对应的一行\n",
    "        one_row = self.read_data.iloc[index]\n",
    "        user_index = self.user_id_to_index[one_row['User']]\n",
    "        book_index = self.book_id_to_index[one_row['Book']]\n",
    "        u_b_rating = one_row['Rate'].astype('float32')\n",
    "        #返回 index\n",
    "        return user_index, book_index, u_b_rating\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#划分数据集，这里我们使用助教样例代码中的train_test_split\n",
    "train_data, test_data = train_test_split(read_data, test_size=0.5, random_state=42)\n",
    "\n",
    "#创建数据集\n",
    "all_dataset = BookScoreDataSet(read_data)\n",
    "train_dataset = BookScoreDataSet(train_data, all_dataset)\n",
    "test_dataset = BookScoreDataSet(test_data, all_dataset)\n",
    "\n",
    "#创建训练和测试数据迭代器，批量大小设置为256\n",
    "batch_size = 256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础的基于MSE损失的 MF 模型\n",
    "class BaseMSEMFModel(nn.Module):\n",
    "    def __init__(self, factor_dim, users_nums, books_nums):\n",
    "        super(BaseMSEMFModel, self).__init__()\n",
    "        self.user_matrix = nn.Embedding(users_nums, factor_dim)\n",
    "        self.book_matrix = nn.Embedding(books_nums, factor_dim)\n",
    "\n",
    "    # 前向传播函数，得到预测评分值   \n",
    "    def forward(self, X):\n",
    "        user_index, book_index = X\n",
    "        user_vector = self.user_matrix(user_index)\n",
    "        book_vector = self.book_matrix(book_index)\n",
    "        # 经过Embedding层出来的vector形状应该是（batch_size x factor_dim）\n",
    "        # 做点积，得到（batch_size X 1）的预测评分\n",
    "        return (user_vector * book_vector).sum(dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是主函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(net, loss, train_iter, test_iter, batch_size, device, num_epochs = 40, lr = 0.02):\n",
    "    # 定义优化器为 SGD \n",
    "    trainer = torch.optim.SGD(net.parameters(), lr = lr)\n",
    "    # 正则化超参数，这里使用样例代码中的0.001，省去调参的工作\n",
    "    lambda_1 = 0.001\n",
    "    lambda_2 = 0.001\n",
    "    # 迭代训练，每一个 epoch 打印 train loss 、test loss and test ndcg_score\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for i, X in enumerate(train_iter):\n",
    "            user_index, book_index, u_b_rating = X \n",
    "            # 梯度清零\n",
    "            trainer.zero_grad()\n",
    "            X = (user_index.to(device),book_index.to(device))\n",
    "            # 模型预测\n",
    "            hat_rate = net(X)\n",
    "\n",
    "            # 计算损失，加入L2范数进行正则化\n",
    "            l = loss(hat_rate, u_b_rating.to(device)).mean() + lambda_1 * net.user_matrix.weight.norm(2) \n",
    "            + lambda_2 * net.book_matrix.weight.norm(2)\n",
    "\n",
    "            train_loss += l\n",
    "            # 反向传播\n",
    "            l.backward()\n",
    "            # 更新参数\n",
    "            trainer.step()\n",
    "\n",
    "        train_loss /= i+1\n",
    "\n",
    "        # 测试评估\n",
    "        net.eval()\n",
    "        test_loss = 0.0\n",
    "        results = []\n",
    "        with torch.no_grad():\n",
    "            for i, X in enumerate(test_iter):\n",
    "                user_index, book_index, u_b_rating = X\n",
    "                X = (user_index.to(device),book_index.to(device))\n",
    "                #得到预测得分\n",
    "                predict_rate = net(X)\n",
    "                #计算损失\n",
    "                l = loss(predict_rate, u_b_rating.to(device)).mean()\n",
    "                test_loss += l\n",
    "\n",
    "                #下面计算测试集的ndcg_socre，来评估预测的排序的效果\n",
    "                res = torch.cat([user_index.unsqueeze(1), predict_rate.cpu().unsqueeze(1), u_b_rating.unsqueeze(1)], dim = 1)\n",
    "                results.append(res)\n",
    "\n",
    "            # results变为一个(num_test_instance, 3)的张量\n",
    "            results = torch.stack(results, dim = 0)\n",
    "            results = results.flatten(start_dim=0, end_dim=1)\n",
    "            # 对不同用户分组，分别计算ndcg\n",
    "            # 将 user_index, predict_rate 和 u_b_rating 拆分开\n",
    "            user_indexs = results[:, 0].long()   # 用户 index\n",
    "            pred_ratings = results[:, 1]         # 预测评分\n",
    "            true_ratings = results[:, 2]         # 真实评分\n",
    "\n",
    "            # 将用户 ID 转换为 numpy 数组，方便后续操作\n",
    "            user_indexs_np = user_indexs.cpu().numpy()\n",
    "            pred_ratings_np = pred_ratings.cpu().numpy()\n",
    "            true_ratings_np = true_ratings.cpu().numpy()\n",
    "\n",
    "            # 为每个用户计算 NDCG 分数\n",
    "            ndcg_scores = []\n",
    "\n",
    "            # 获取每个用户的唯一 index\n",
    "            unique_users = np.unique(user_indexs_np)\n",
    "\n",
    "            for user in unique_users:\n",
    "                # 获取当前用户的所有评分数据\n",
    "                user_true_ratings = true_ratings_np[user_indexs_np == user]\n",
    "                user_pred_ratings = pred_ratings_np[user_indexs_np == user]\n",
    "                \n",
    "                # 计算该用户的 NDCG 分数\n",
    "                if len(user_true_ratings) > 1:\n",
    "                    # ndcg@k，k取样例代码中的50\n",
    "                    ndcg = ndcg_score([user_true_ratings], [user_pred_ratings], k=50)\n",
    "                    ndcg_scores.append(torch.from_numpy(np.array(ndcg)))\n",
    "\n",
    "            # 将所有用户的 NDCG 分数存储在一个张量中\n",
    "            ndcg_scores = torch.stack(ndcg_scores)\n",
    "\n",
    "            # 计算平均 ndcg\n",
    "            ndcg_score_ = ndcg_scores.mean()\n",
    "            \n",
    "            test_loss /= i+1\n",
    "        # print protocols\n",
    "        print(f'At epoch {epoch}, train_loss {train_loss}, test_loss {test_loss}, ndcg_score {ndcg_score_}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0, train_loss 57.95421600341797, test_loss 54.245155334472656, ndcg_score 0.6659922719093427\n",
      "At epoch 1, train_loss 50.45396423339844, test_loss 49.0337028503418, ndcg_score 0.6662685862917689\n",
      "At epoch 2, train_loss 44.644412994384766, test_loss 44.885650634765625, ndcg_score 0.6664776106435555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m net \u001b[38;5;241m=\u001b[39m BaseMSEMFModel(\u001b[38;5;241m50\u001b[39m, users_nums, books_nums)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m main(net, loss, train_iter, test_iter, batch_size, device)\n",
      "Cell \u001b[1;32mIn[17], line 37\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(net, loss, train_iter, test_iter, batch_size, device, num_epochs, lr)\u001b[0m\n\u001b[0;32m     35\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, X \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_iter):\n\u001b[0;32m     38\u001b[0m         user_index, book_index, u_b_rating \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     39\u001b[0m         X \u001b[38;5;241m=\u001b[39m (user_index\u001b[38;5;241m.\u001b[39mto(device),book_index\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    627\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\profiler.py:705\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m--> 705\u001b[0m         torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit\u001b[38;5;241m.\u001b[39m_RecordFunction(record)\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\_ops.py:903\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[1;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_dispatch_in_python(\n\u001b[0;32m    901\u001b[0m             args, kwargs, self_\u001b[38;5;241m.\u001b[39m_fallthrough_keys()\n\u001b[0;32m    902\u001b[0m         )\n\u001b[1;32m--> 903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BaseMSEMFModel(50, users_nums, books_nums).to(device)\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "main(net, loss, train_iter, test_iter, batch_size, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
