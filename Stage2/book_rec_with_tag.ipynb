{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bert Model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "model = BertModel.from_pretrained('bert-base-chinese').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Tag Embeddings\n",
    "loaded_data = pd.read_csv('data\\selected_book_top_1200_data_tag.csv')\n",
    "\n",
    "tag_embedding_dict = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, rows in tqdm(loaded_data.iterrows()):\n",
    "        # Convert tag list to string\n",
    "        tags_str = \" \".join(rows.Tags)\n",
    "        # Use BERT to get tag embedding\n",
    "        inputs = tokenizer(tags_str, truncation=True, return_tensors='pt')\n",
    "        outputs = model(inputs.input_ids.cuda(), inputs.token_type_ids.cuda(), inputs.attention_mask.cuda())\n",
    "        tag_embedding = outputs.last_hidden_state.mean(dim=1).cpu()\n",
    "        tag_embedding_dict[rows.Book] = tag_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings dict\n",
    "with open('data/tag_embedding_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(tag_embedding_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings dict\n",
    "with open('data/tag_embedding_dict.pkl', 'rb') as f:\n",
    "    tag_embedding_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Score Tag Embeddings\n",
    "loaded_data = pd.read_csv('data\\\\book_score.csv')\n",
    "\n",
    "rating_embedding_dict = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, rows in tqdm(loaded_data.iterrows()):\n",
    "        # Convert tag list to string\n",
    "        tags_str = \" \".join(rows.Tags)\n",
    "        # Use BERT to get tag embedding\n",
    "        inputs = tokenizer(tags_str, truncation=True, return_tensors='pt')\n",
    "        outputs = model(inputs.input_ids.cuda(), inputs.token_type_ids.cuda(), inputs.attention_mask.cuda())\n",
    "        tag_embedding = outputs.last_hidden_state.mean(dim=1).cpu()\n",
    "        rating_embedding_dict[(rows.User, rows.Book)] = tag_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rating embeddings dict\n",
    "with open('data/rating_embedding_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(rating_embedding_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rating embeddings dict\n",
    "with open('data/rating_embedding_dict.pkl', 'rb') as f:\n",
    "    rating_embedding_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Class\n",
    "class BookRatingDataset(Dataset):\n",
    "    def __init__(self, data, user_idx, book_idx, tag_embedding_dict, rating_embedding_dict):\n",
    "        self.data = data\n",
    "        self.user_idx = user_idx\n",
    "        self.book_idx = book_idx\n",
    "        self.tag_embedding_dict = tag_embedding_dict\n",
    "        self.rating_embedding_dict = rating_embedding_dict\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        user = self.user_idx[row['User']]\n",
    "        book = self.book_idx[row['Book']]\n",
    "        rating = row['Rate'].astype('float32')\n",
    "        tag_embedding = self.tag_embedding_dict[row['Book']]\n",
    "        rating_embedding = self.rating_embedding_dict[(row['User'], row['Book'])]\n",
    "        return user, book, rating, tag_embedding, rating_embedding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "class RatingPredictionModel(nn.Module):\n",
    "    def __init__(self, user_count, book_count, entity_embeddings_dim, text_embeddings_dim):\n",
    "        super(RatingPredictionModel, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(user_count, entity_embeddings_dim)\n",
    "        self.book_embeddings = nn.Embedding(book_count, entity_embeddings_dim)\n",
    "        self.book_tag_embeddings = nn.Linear(text_embeddings_dim, entity_embeddings_dim)\n",
    "        self.rating_tag_embeddings = nn.Linear(text_embeddings_dim, entity_embeddings_dim)\n",
    "        self.predict_rating = nn.Linear(entity_embeddings_dim * 4, 1)\n",
    "    \n",
    "    def forward(self, user, book, tag_embedding, rating_embedding):\n",
    "        user_embedding = self.user_embeddings(user)\n",
    "        book_embedding = self.book_embeddings(book)\n",
    "        book_tag_embedding = self.book_tag_embeddings(tag_embedding)\n",
    "        rating_tag_embedding = self.rating_tag_embeddings(rating_embedding)  \n",
    "        book_embeddings_integrated = torch.cat([user_embedding, book_embedding, book_tag_embedding, rating_tag_embedding], dim=1)\n",
    "        return self.predict_rating(book_embeddings_integrated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
