{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这是基于`BPR:Bayesian Personalized Ranking`实现的`Matrix Factorization`的协同过滤算法来进行的书籍评分的预测\n",
    "### BPR是一种 `pair-wise`的方法，在个性化排序的任务上表现很好，所以我们使用`BPR`来与其他方法进行对比\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库\n",
    "import torch \n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.functional as F\n",
    "#sklearn库\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User     Book  Rate                       Time         Tag\n",
      "0       1398478  1467022     0  2011-03-29T12:48:35+08:00         NaN\n",
      "1       1398478  1777823     0  2011-02-02T21:58:55+08:00         NaN\n",
      "2       1398478  1902628     0  2011-01-31T15:57:58+08:00         NaN\n",
      "3       1398478  1878708     0  2011-01-26T11:27:59+08:00         NaN\n",
      "4       1398478  4238362     0  2011-01-21T13:04:15+08:00         NaN\n",
      "...         ...      ...   ...                        ...         ...\n",
      "637249  4507957  1125186     4  2009-07-04T08:02:13+08:00  张爱玲,半生缘,爱情\n",
      "637250  4507957  1002299     5  2009-07-04T08:01:28+08:00  金庸,武侠,笑傲江湖\n",
      "637251  4507957  1001136     4  2009-07-04T07:55:17+08:00     彼得・潘,童话\n",
      "637252  4507957  1021615     5  2009-07-04T07:53:54+08:00   小王子,童话,经典\n",
      "637253  4507957  1962929     5  2009-06-29T22:13:37+08:00          爱情\n",
      "\n",
      "[637254 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#读取book_score_csv\n",
    "file_path = ('data/book_score.csv')\n",
    "read_data = pd.read_csv(file_path)\n",
    "print(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#用户和书籍的个数，构建 P Q 矩阵需要\n",
    "users_nums = len(read_data['User'].unique())\n",
    "books_nums = len(read_data['Book'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个用户未评过分的书籍列表，用于充当负例\n",
    "all_books = read_data['Book'].unique()\n",
    "user_books = read_data.groupby('User')['Book'].unique()\n",
    "\n",
    "user_unrated_books = {}\n",
    "for user, rated_books in user_books.items():\n",
    "    # 找到用户没有评价过的书籍\n",
    "    unrated_books = list(set(all_books) - set(rated_books))\n",
    "    user_unrated_books[user] = unrated_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己的书籍评分数据集类，返回用户 id的index ，评过分和未评过分的书籍 id的index , 以及对应的评分\n",
    "class BookScoreDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, read_data, user_unrated_books, all_dataset = None):\n",
    "        self.read_data = read_data\n",
    "        if all_dataset == None:\n",
    "            #依据字典索引得到 user 和 book 的 id 列表\n",
    "            self.users_unique_id_list = read_data['User'].unique()\n",
    "            self.books_unique_id_list = read_data['Book'].unique()\n",
    "            self.users_unique_id_list = sorted(set(self.users_unique_id_list))\n",
    "            self.books_unique_id_list = sorted(set(self.books_unique_id_list))\n",
    "            #依据id列表，创建 user 和 book 的分别从 id 到 index 的转换，便于实现利用索引访问对应的矩阵 factor\n",
    "            self.user_id_to_index = {id : index for index, id in enumerate(self.users_unique_id_list)}\n",
    "            self.book_id_to_index = {id : index for index, id in enumerate(self.books_unique_id_list)}\n",
    "            self.user_unrated_books = user_unrated_books\n",
    "        else:\n",
    "            self.user_id_to_index = all_dataset.user_id_to_index\n",
    "            self.book_id_to_index = all_dataset.book_id_to_index\n",
    "            self.user_unrated_books = all_dataset.user_unrated_books\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # 返回（user, rated_book, unrated_book）三元组，附带真实评分\n",
    "        # 得到数据文件中index对应的一行\n",
    "        one_row = self.read_data.iloc[index]\n",
    "        user_index = self.user_id_to_index[one_row['User']]\n",
    "        rated_book_index = self.book_id_to_index[one_row['Book']]\n",
    "        u_b_rating = one_row['Rate'].astype('float32')\n",
    "        unrated_book_index = self.book_id_to_index[random.choice(self.user_unrated_books[one_row['User']])]\n",
    "        #返回 index\n",
    "        return user_index, rated_book_index, unrated_book_index, u_b_rating\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#划分数据集，这里我们使用助教样例代码中的train_test_split\n",
    "train_data, test_data = train_test_split(read_data, test_size=0.5, random_state=42)\n",
    "\n",
    "#创建数据集\n",
    "all_dataset = BookScoreDataSet(read_data, user_unrated_books)\n",
    "train_dataset = BookScoreDataSet(train_data, user_unrated_books, all_dataset)\n",
    "test_dataset = BookScoreDataSet(test_data, user_unrated_books, all_dataset)\n",
    "\n",
    "#创建训练和测试数据迭代器\n",
    "batch_size = 256\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 BPR 的 MF 模型\n",
    "class BPRMFModel(nn.Module):\n",
    "    def __init__(self, factor_dim, users_nums, books_nums):\n",
    "        super(BPRMFModel, self).__init__()\n",
    "        self.user_matrix = nn.Embedding(users_nums, factor_dim)\n",
    "        self.book_matrix = nn.Embedding(books_nums, factor_dim)\n",
    "\n",
    "    # 前向传播函数，得到预测评分值   \n",
    "    def forward(self, X):\n",
    "        user_index, rated_book_index, unrated_book_index = X\n",
    "        user_vector = self.user_matrix(user_index)\n",
    "        rated_book_vector = self.book_matrix(rated_book_index)\n",
    "        unrated_book_vector = self.book_matrix(unrated_book_index)\n",
    "        # 经过Embedding层出来的vector形状应该是（batch_size x factor_dim）\n",
    "        # 做点积，得到（batch_size X 1）的预测评分\n",
    "        return (user_vector * rated_book_vector).sum(dim = 1), (user_vector * unrated_book_vector).sum(dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是主函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(net, train_iter, test_iter, batch_size, device, factor_dim, num_epochs = 40, lr = 0.01):\n",
    "    # 正则化超参数\n",
    "    lambda_1 = 0.0001\n",
    "    # 迭代训练，每一个 epoch 打印 ndcg_score\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        net.train()\n",
    "        results = []\n",
    "        for i, X in enumerate(train_iter):\n",
    "            user_index, rated_book_index, unrated_book_index, u_b_rating = X \n",
    "            X = (user_index.to(device),rated_book_index.to(device),unrated_book_index.to(device))\n",
    "\n",
    "            # 模型预测\n",
    "            hat_rate_rated, hat_rate_unrated= net(X)\n",
    "            # 目标函数为 BPR_opt\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # 使用 SGD 手动更新参数\n",
    "                # print(torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).shape)\n",
    "                net.user_matrix.weight[user_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (net.book_matrix.weight[rated_book_index] - net.book_matrix.weight[unrated_book_index]) +\n",
    "                lambda_1 * net.user_matrix.weight[user_index])\n",
    "\n",
    "                net.book_matrix.weight[rated_book_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (net.user_matrix.weight[user_index]) +\n",
    "                lambda_1 * net.book_matrix.weight[rated_book_index])\n",
    "\n",
    "                net.book_matrix.weight[unrated_book_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (-net.user_matrix.weight[user_index]) +\n",
    "                lambda_1 * net.book_matrix.weight[unrated_book_index])\n",
    "                \n",
    "                res = torch.cat([user_index.unsqueeze(1), torch.nan_to_num(hat_rate_rated).cpu().unsqueeze(1), u_b_rating.unsqueeze(1)], dim = 1)\n",
    "                results.append(res)\n",
    "        with torch.no_grad():\n",
    "            # results变为一个(num_test_instance, 3)的张量\n",
    "            results = torch.stack(results, dim = 0)\n",
    "            results = results.flatten(start_dim=0, end_dim=1)\n",
    "            # 对不同用户分组，分别计算ndcg\n",
    "            # 将 user_index, predict_rate 和 u_b_rating 拆分开\n",
    "            user_indexs = results[:, 0].long()   # 用户 index\n",
    "            pred_ratings = results[:, 1]         # 预测评分\n",
    "            true_ratings = results[:, 2]         # 真实评分\n",
    "\n",
    "            # 将用户 ID 转换为 numpy 数组，方便后续操作\n",
    "            user_indexs_np = user_indexs.cpu().numpy()\n",
    "            pred_ratings_np = pred_ratings.cpu().numpy()\n",
    "            true_ratings_np = true_ratings.cpu().numpy()\n",
    "\n",
    "            # 为每个用户计算 NDCG 分数\n",
    "            ndcg_scores = []\n",
    "\n",
    "            # 获取每个用户的唯一 index\n",
    "            unique_users = np.unique(user_indexs_np)\n",
    "\n",
    "            for user in unique_users:\n",
    "                # 获取当前用户的所有评分数据\n",
    "                user_true_ratings = true_ratings_np[user_indexs_np == user]\n",
    "                user_pred_ratings = pred_ratings_np[user_indexs_np == user]\n",
    "                    \n",
    "                # 计算该用户的 NDCG 分数\n",
    "                if len(user_true_ratings) > 1:\n",
    "                    # ndcg@k，k取样例代码中的50\n",
    "                    ndcg = ndcg_score([np.nan_to_num(user_true_ratings)], [np.nan_to_num(user_pred_ratings)], k=50)\n",
    "                    ndcg_scores.append(torch.from_numpy(np.array(ndcg)))\n",
    "\n",
    "            # 将所有用户的 NDCG 分数存储在一个张量中\n",
    "            ndcg_scores = torch.stack(ndcg_scores)\n",
    "\n",
    "            # 计算平均 ndcg\n",
    "            ndcg_score_train = ndcg_scores.mean()\n",
    "\n",
    "        # 测试评估\n",
    "        net.eval()\n",
    "        results = []\n",
    "        with torch.no_grad():\n",
    "            for i, X in enumerate(test_iter):\n",
    "                user_index, rated_book_index, unrated_book_index, u_b_rating = X \n",
    "                X = (user_index.to(device),rated_book_index.to(device),unrated_book_index.to(device))\n",
    "\n",
    "                #得到预测得分\n",
    "                predict_rate_rated, predict_rate_unrated = net(X)\n",
    "\n",
    "                #下面计算测试集的ndcg_socre，来评估预测的排序的效果\n",
    "                res = torch.cat([user_index.unsqueeze(1), torch.nan_to_num(predict_rate_rated).cpu().unsqueeze(1), u_b_rating.unsqueeze(1)], dim = 1)\n",
    "                results.append(res)\n",
    "\n",
    "            # results变为一个(num_test_instance, 3)的张量\n",
    "            results = torch.stack(results, dim = 0)\n",
    "            results = results.flatten(start_dim=0, end_dim=1)\n",
    "            # 对不同用户分组，分别计算ndcg\n",
    "            # 将 user_index, predict_rate 和 u_b_rating 拆分开\n",
    "            user_indexs = results[:, 0].long()   # 用户 index\n",
    "            pred_ratings = results[:, 1]         # 预测评分\n",
    "            true_ratings = results[:, 2]         # 真实评分\n",
    "\n",
    "            # 将用户 ID 转换为 numpy 数组，方便后续操作\n",
    "            user_indexs_np = user_indexs.cpu().numpy()\n",
    "            pred_ratings_np = pred_ratings.cpu().numpy()\n",
    "            true_ratings_np = true_ratings.cpu().numpy()\n",
    "\n",
    "            # 为每个用户计算 NDCG 分数\n",
    "            ndcg_scores = []\n",
    "\n",
    "            # 获取每个用户的唯一 index\n",
    "            unique_users = np.unique(user_indexs_np)\n",
    "\n",
    "            for user in unique_users:\n",
    "                # 获取当前用户的所有评分数据\n",
    "                user_true_ratings = true_ratings_np[user_indexs_np == user]\n",
    "                user_pred_ratings = pred_ratings_np[user_indexs_np == user]\n",
    "                \n",
    "                # 计算该用户的 NDCG 分数\n",
    "                if len(user_true_ratings) > 1:\n",
    "                    # ndcg@k，k取样例代码中的50\n",
    "                    ndcg = ndcg_score([np.nan_to_num(user_true_ratings)], [np.nan_to_num(user_pred_ratings)], k=50)\n",
    "                    ndcg_scores.append(torch.from_numpy(np.array(ndcg)))\n",
    "\n",
    "            # 将所有用户的 NDCG 分数存储在一个张量中\n",
    "            ndcg_scores = torch.stack(ndcg_scores)\n",
    "\n",
    "            # 计算平均 ndcg\n",
    "            ndcg_score_test = ndcg_scores.mean()\n",
    "            \n",
    "        # print protocols\n",
    "        print(f'At epoch {epoch}, train_ndcg_score {ndcg_score_train}, test_ndcg_score {ndcg_score_test}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0, train_ndcg_score 0.6665460042314573, test_ndcg_score 0.6677792442567383\n",
      "At epoch 1, train_ndcg_score 0.6673478355760913, test_ndcg_score 0.6677531008103439\n",
      "At epoch 2, train_ndcg_score 0.6667947399621399, test_ndcg_score 0.6675690933551122\n",
      "At epoch 3, train_ndcg_score 0.6661927036613204, test_ndcg_score 0.6669703597606624\n",
      "At epoch 4, train_ndcg_score 0.6654461003845512, test_ndcg_score 0.6658823574683265\n",
      "At epoch 5, train_ndcg_score 0.6641641685615091, test_ndcg_score 0.6650044237545202\n",
      "At epoch 6, train_ndcg_score 0.6635966364665413, test_ndcg_score 0.6643149839313419\n",
      "At epoch 7, train_ndcg_score 0.6637483674266322, test_ndcg_score 0.6631299738615176\n",
      "At epoch 8, train_ndcg_score 0.6616152483541621, test_ndcg_score 0.6623931349936059\n",
      "At epoch 9, train_ndcg_score 0.6617445722201994, test_ndcg_score 0.6629822403756375\n",
      "At epoch 10, train_ndcg_score 0.6610316512929812, test_ndcg_score 0.6627707213459415\n",
      "At epoch 11, train_ndcg_score 0.6608687747495189, test_ndcg_score 0.6636164198775922\n",
      "At epoch 12, train_ndcg_score 0.6602317721207315, test_ndcg_score 0.6636923454536083\n",
      "At epoch 13, train_ndcg_score 0.6618448639095681, test_ndcg_score 0.663348506855851\n",
      "At epoch 14, train_ndcg_score 0.6622025543880801, test_ndcg_score 0.6635428758908647\n",
      "At epoch 15, train_ndcg_score 0.6623903380388517, test_ndcg_score 0.6634667303121429\n",
      "At epoch 16, train_ndcg_score 0.6624406200831976, test_ndcg_score 0.6634577487519796\n",
      "At epoch 17, train_ndcg_score 0.6626941061655335, test_ndcg_score 0.6636368512589371\n",
      "At epoch 18, train_ndcg_score 0.6626953555286993, test_ndcg_score 0.663567990875332\n",
      "At epoch 19, train_ndcg_score 0.6637178693095038, test_ndcg_score 0.6639860422678695\n",
      "At epoch 20, train_ndcg_score 0.6635703415892165, test_ndcg_score 0.6641323665800503\n",
      "At epoch 21, train_ndcg_score 0.6642518519636332, test_ndcg_score 0.6649267787575639\n",
      "At epoch 22, train_ndcg_score 0.6643167563076536, test_ndcg_score 0.6653705319884688\n",
      "At epoch 23, train_ndcg_score 0.6641218906205688, test_ndcg_score 0.6643117143886921\n",
      "At epoch 24, train_ndcg_score 0.6636645847377143, test_ndcg_score 0.6638630357066851\n",
      "At epoch 25, train_ndcg_score 0.6641381458348539, test_ndcg_score 0.6646172250646131\n",
      "At epoch 26, train_ndcg_score 0.6641746584987305, test_ndcg_score 0.664891751181013\n",
      "At epoch 27, train_ndcg_score 0.6651581718953307, test_ndcg_score 0.6647604417624118\n",
      "At epoch 28, train_ndcg_score 0.665087869935383, test_ndcg_score 0.6645768830419558\n",
      "At epoch 29, train_ndcg_score 0.6650185790964155, test_ndcg_score 0.6655817262017274\n",
      "At epoch 30, train_ndcg_score 0.6657666873085816, test_ndcg_score 0.6658732888884629\n",
      "At epoch 31, train_ndcg_score 0.664859137839198, test_ndcg_score 0.6654654115724179\n",
      "At epoch 32, train_ndcg_score 0.664817637010872, test_ndcg_score 0.665689325677643\n",
      "At epoch 33, train_ndcg_score 0.6656988491365958, test_ndcg_score 0.6655947565666921\n",
      "At epoch 34, train_ndcg_score 0.6657132467558065, test_ndcg_score 0.6659707161359588\n",
      "At epoch 35, train_ndcg_score 0.6658274041671419, test_ndcg_score 0.665695529352672\n",
      "At epoch 36, train_ndcg_score 0.6659370016030979, test_ndcg_score 0.6654370296652914\n",
      "At epoch 37, train_ndcg_score 0.6656362554361459, test_ndcg_score 0.6661208748104035\n",
      "At epoch 38, train_ndcg_score 0.6662021184846784, test_ndcg_score 0.6658483974786839\n",
      "At epoch 39, train_ndcg_score 0.6665459752023192, test_ndcg_score 0.6655038527965574\n"
     ]
    }
   ],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "factor_dim = 50\n",
    "net = BPRMFModel(factor_dim, users_nums, books_nums).to(device)\n",
    "main(net, train_iter, test_iter, batch_size, device, factor_dim=factor_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
