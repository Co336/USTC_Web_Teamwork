{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这是基于`BPR:Bayesian Personalized Ranking`实现的`Matrix Factorization`的协同过滤算法来进行的书籍评分的预测\n",
    "### BPR是一种 `pair-wise`的方法，在个性化排序的任务上表现很好，所以我们使用`BPR`来与其他方法进行对比\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库\n",
    "import torch \n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.functional as F\n",
    "#sklearn库\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User     Book  Rate                       Time         Tag\n",
      "0       1398478  1467022     0  2011-03-29T12:48:35+08:00         NaN\n",
      "1       1398478  1777823     0  2011-02-02T21:58:55+08:00         NaN\n",
      "2       1398478  1902628     0  2011-01-31T15:57:58+08:00         NaN\n",
      "3       1398478  1878708     0  2011-01-26T11:27:59+08:00         NaN\n",
      "4       1398478  4238362     0  2011-01-21T13:04:15+08:00         NaN\n",
      "...         ...      ...   ...                        ...         ...\n",
      "637249  4507957  1125186     4  2009-07-04T08:02:13+08:00  张爱玲,半生缘,爱情\n",
      "637250  4507957  1002299     5  2009-07-04T08:01:28+08:00  金庸,武侠,笑傲江湖\n",
      "637251  4507957  1001136     4  2009-07-04T07:55:17+08:00     彼得・潘,童话\n",
      "637252  4507957  1021615     5  2009-07-04T07:53:54+08:00   小王子,童话,经典\n",
      "637253  4507957  1962929     5  2009-06-29T22:13:37+08:00          爱情\n",
      "\n",
      "[637254 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#读取book_score_csv\n",
    "file_path = ('data/book_score.csv')\n",
    "read_data = pd.read_csv(file_path)\n",
    "print(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#用户和书籍的个数，构建 P Q 矩阵需要\n",
    "users_nums = len(read_data['User'].unique())\n",
    "books_nums = len(read_data['Book'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个用户未评过分的书籍列表，用于充当负例\n",
    "all_books = read_data['Book'].unique()\n",
    "user_books = read_data.groupby('User')['Book'].unique()\n",
    "\n",
    "user_unrated_books = {}\n",
    "for user, rated_books in user_books.items():\n",
    "    # 找到用户没有评价过的书籍\n",
    "    unrated_books = list(set(all_books) - set(rated_books))\n",
    "    user_unrated_books[user] = unrated_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己的书籍评分数据集类，返回用户 id的index ，评过分和未评过分的书籍 id的index , 以及对应的评分\n",
    "class BookScoreDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, read_data, user_unrated_books, all_dataset = None):\n",
    "        self.read_data = read_data\n",
    "        if all_dataset == None:\n",
    "            #依据字典索引得到 user 和 book 的 id 列表\n",
    "            self.users_unique_id_list = read_data['User'].unique()\n",
    "            self.books_unique_id_list = read_data['Book'].unique()\n",
    "            self.users_unique_id_list = sorted(set(self.users_unique_id_list))\n",
    "            self.books_unique_id_list = sorted(set(self.books_unique_id_list))\n",
    "            #依据id列表，创建 user 和 book 的分别从 id 到 index 的转换，便于实现利用索引访问对应的矩阵 factor\n",
    "            self.user_id_to_index = {id : index for index, id in enumerate(self.users_unique_id_list)}\n",
    "            self.book_id_to_index = {id : index for index, id in enumerate(self.books_unique_id_list)}\n",
    "            self.user_unrated_books = user_unrated_books\n",
    "        else:\n",
    "            self.user_id_to_index = all_dataset.user_id_to_index\n",
    "            self.book_id_to_index = all_dataset.book_id_to_index\n",
    "            self.user_unrated_books = all_dataset.user_unrated_books\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # 返回（user, rated_book, unrated_book）三元组，附带真实评分\n",
    "        # 得到数据文件中index对应的一行\n",
    "        one_row = self.read_data.iloc[index]\n",
    "        user_index = self.user_id_to_index[one_row['User']]\n",
    "        rated_book_index = self.book_id_to_index[one_row['Book']]\n",
    "        u_b_rating = one_row['Rate'].astype('float32')\n",
    "        unrated_book_index = self.book_id_to_index[random.choice(self.user_unrated_books[one_row['User']])]\n",
    "        #返回 index\n",
    "        return user_index, rated_book_index, unrated_book_index, u_b_rating\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#划分数据集，这里我们使用助教样例代码中的train_test_split\n",
    "train_data, test_data = train_test_split(read_data, test_size=0.5, random_state=42)\n",
    "\n",
    "#创建数据集\n",
    "all_dataset = BookScoreDataSet(read_data, user_unrated_books)\n",
    "train_dataset = BookScoreDataSet(train_data, user_unrated_books, all_dataset)\n",
    "test_dataset = BookScoreDataSet(test_data, user_unrated_books, all_dataset)\n",
    "\n",
    "#创建训练和测试数据迭代器\n",
    "batch_size = 8\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于 BPR 的 MF 模型\n",
    "class BPRMFModel(nn.Module):\n",
    "    def __init__(self, factor_dim, users_nums, books_nums):\n",
    "        super(BPRMFModel, self).__init__()\n",
    "        self.user_matrix = nn.Embedding(users_nums, factor_dim)\n",
    "        self.book_matrix = nn.Embedding(books_nums, factor_dim)\n",
    "\n",
    "    # 前向传播函数，得到预测评分值   \n",
    "    def forward(self, X):\n",
    "        user_index, rated_book_index, unrated_book_index = X\n",
    "        user_vector = self.user_matrix(user_index)\n",
    "        rated_book_vector = self.book_matrix(rated_book_index)\n",
    "        unrated_book_vector = self.book_matrix(unrated_book_index)\n",
    "        # 经过Embedding层出来的vector形状应该是（batch_size x factor_dim）\n",
    "        # 做点积，得到（batch_size X 1）的预测评分\n",
    "        return (user_vector * rated_book_vector).sum(dim = 1), (user_vector * unrated_book_vector).sum(dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是主函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(net, train_iter, test_iter, batch_size, device, factor_dim, num_epochs = 40, lr = 0.04):\n",
    "    # 正则化超参数\n",
    "    lambda_1 = 0.001\n",
    "    # 迭代训练，每一个 epoch 打印 ndcg_score\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        net.train()\n",
    "        for i, X in enumerate(train_iter):\n",
    "            user_index, rated_book_index, unrated_book_index, u_b_rating = X \n",
    "            X = (user_index.to(device),rated_book_index.to(device),unrated_book_index.to(device))\n",
    "\n",
    "            # 模型预测\n",
    "            hat_rate_rated, hat_rate_unrated= net(X)\n",
    "            # 目标函数为 BPR_opt\n",
    "            with torch.no_grad():\n",
    "                # 使用SGD手动更新参数\n",
    "                # print(torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).shape)\n",
    "                net.user_matrix.weight[user_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (net.book_matrix.weight[rated_book_index] - net.book_matrix.weight[unrated_book_index]) +\n",
    "                lambda_1 * net.user_matrix.weight[user_index])\n",
    "\n",
    "                net.book_matrix.weight[rated_book_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (net.user_matrix.weight[user_index]) +\n",
    "                lambda_1 * net.book_matrix.weight[rated_book_index])\n",
    "\n",
    "                net.book_matrix.weight[unrated_book_index] += lr * (torch.sigmoid(-(hat_rate_rated - hat_rate_unrated)).unsqueeze(1).repeat(1, factor_dim) * \n",
    "                (-net.user_matrix.weight[user_index]) +\n",
    "                lambda_1 * net.book_matrix.weight[unrated_book_index])\n",
    "        # 测试评估\n",
    "        net.eval()\n",
    "        results = []\n",
    "        with torch.no_grad():\n",
    "            for i, X in enumerate(test_iter):\n",
    "                user_index, rated_book_index, unrated_book_index, u_b_rating = X \n",
    "                X = (user_index.to(device),rated_book_index.to(device),unrated_book_index.to(device))\n",
    "\n",
    "                #得到预测得分\n",
    "                predict_rate_rated, predict_rate_unrated = net(X)\n",
    "\n",
    "                #下面计算测试集的ndcg_socre，来评估预测的排序的效果\n",
    "                res = torch.cat([user_index.unsqueeze(1), predict_rate_rated.cpu().unsqueeze(1), u_b_rating.unsqueeze(1)], dim = 1)\n",
    "                results.append(res)\n",
    "\n",
    "            # results变为一个(num_test_instance, 3)的张量\n",
    "            results = torch.stack(results, dim = 0)\n",
    "            # 对不同用户分组，分别计算ndcg\n",
    "            # 将 user_index, predict_rate 和 u_b_rating 拆分开\n",
    "            user_indexs = results[:, 0].long()   # 用户 index\n",
    "            pred_ratings = results[:, 1]         # 预测评分\n",
    "            true_ratings = results[:, 2]         # 真实评分\n",
    "\n",
    "            # 将用户 ID 转换为 numpy 数组，方便后续操作\n",
    "            user_indexs_np = user_indexs.cpu().numpy()\n",
    "            pred_ratings_np = pred_ratings.cpu().numpy()\n",
    "            true_ratings_np = true_ratings.cpu().numpy()\n",
    "\n",
    "            # 为每个用户计算 NDCG 分数\n",
    "            ndcg_scores = []\n",
    "\n",
    "            # 获取每个用户的唯一 index\n",
    "            unique_users = np.unique(user_indexs_np)\n",
    "\n",
    "            for user in unique_users:\n",
    "                # 获取当前用户的所有评分数据\n",
    "                user_true_ratings = true_ratings_np[user_indexs_np == user]\n",
    "                user_pred_ratings = pred_ratings_np[user_indexs_np == user]\n",
    "                user_true_ratings_abs = np.abs(user_true_ratings)\n",
    "                \n",
    "                # 计算该用户的 NDCG 分数\n",
    "                if len(user_true_ratings_abs) > 1:\n",
    "                    # ndcg@k，k取样例代码中的50\n",
    "                    ndcg = ndcg_score([np.nan_to_num(user_true_ratings_abs)], [np.nan_to_num(user_pred_ratings)], k=50)\n",
    "                    ndcg_scores.append(torch.from_numpy(np.array(ndcg)))\n",
    "\n",
    "            # 将所有用户的 NDCG 分数存储在一个张量中\n",
    "            ndcg_scores = torch.stack(ndcg_scores)\n",
    "\n",
    "            # 计算平均 ndcg\n",
    "            ndcg_score_ = ndcg_scores.mean()\n",
    "            \n",
    "        # print protocols\n",
    "        print(f'At epoch {epoch}, ndcg_score {ndcg_score_}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0, ndcg_score 0.8350453978872957\n",
      "At epoch 1, ndcg_score 0.8351739430054276\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m factor_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      3\u001b[0m net \u001b[38;5;241m=\u001b[39m BPRMFModel(factor_dim, users_nums, books_nums)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m main(net, train_iter, test_iter, batch_size, device, factor_dim\u001b[38;5;241m=\u001b[39mfactor_dim)\n",
      "Cell \u001b[1;32mIn[60], line 27\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(net, train_iter, test_iter, batch_size, device, factor_dim, num_epochs, lr)\u001b[0m\n\u001b[0;32m     19\u001b[0m         net\u001b[38;5;241m.\u001b[39muser_matrix\u001b[38;5;241m.\u001b[39mweight[user_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;241m-\u001b[39m(hat_rate_rated \u001b[38;5;241m-\u001b[39m hat_rate_unrated))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, factor_dim) \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m     20\u001b[0m         (net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[rated_book_index] \u001b[38;5;241m-\u001b[39m net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[unrated_book_index]) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     21\u001b[0m         lambda_1 \u001b[38;5;241m*\u001b[39m net\u001b[38;5;241m.\u001b[39muser_matrix\u001b[38;5;241m.\u001b[39mweight[user_index])\n\u001b[0;32m     23\u001b[0m         net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[rated_book_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;241m-\u001b[39m(hat_rate_rated \u001b[38;5;241m-\u001b[39m hat_rate_unrated))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, factor_dim) \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m     24\u001b[0m         (net\u001b[38;5;241m.\u001b[39muser_matrix\u001b[38;5;241m.\u001b[39mweight[user_index]) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     25\u001b[0m         lambda_1 \u001b[38;5;241m*\u001b[39m net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[rated_book_index])\n\u001b[1;32m---> 27\u001b[0m         net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[unrated_book_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;241m-\u001b[39m(hat_rate_rated \u001b[38;5;241m-\u001b[39m hat_rate_unrated))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, factor_dim) \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m     28\u001b[0m         (\u001b[38;5;241m-\u001b[39mnet\u001b[38;5;241m.\u001b[39muser_matrix\u001b[38;5;241m.\u001b[39mweight[user_index]) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     29\u001b[0m         lambda_1 \u001b[38;5;241m*\u001b[39m net\u001b[38;5;241m.\u001b[39mbook_matrix\u001b[38;5;241m.\u001b[39mweight[unrated_book_index])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 测试评估\u001b[39;00m\n\u001b[0;32m     31\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1716\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1709\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1718\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "factor_dim = 20\n",
    "net = BPRMFModel(factor_dim, users_nums, books_nums).to(device)\n",
    "main(net, train_iter, test_iter, batch_size, device, factor_dim=factor_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
