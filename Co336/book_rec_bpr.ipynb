{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们实现了两种基于`Matrix Factorization`的协同过滤算法来进行书籍评分的预测，并会在实验报告中给出两种推荐算法的结果比较分析\n",
    "1. 加入正则项的普通 \\( MSE \\) 矩阵分解算法\n",
    "2. 基于`BPR: Bayesian Personalized Ranking`实现的矩阵分解算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需库\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#sklearn库\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User     Book  Rate                       Time         Tag\n",
      "0       1398478  1467022     0  2011-03-29T12:48:35+08:00         NaN\n",
      "1       1398478  1777823     0  2011-02-02T21:58:55+08:00         NaN\n",
      "2       1398478  1902628     0  2011-01-31T15:57:58+08:00         NaN\n",
      "3       1398478  1878708     0  2011-01-26T11:27:59+08:00         NaN\n",
      "4       1398478  4238362     0  2011-01-21T13:04:15+08:00         NaN\n",
      "...         ...      ...   ...                        ...         ...\n",
      "637249  4507957  1125186     4  2009-07-04T08:02:13+08:00  张爱玲,半生缘,爱情\n",
      "637250  4507957  1002299     5  2009-07-04T08:01:28+08:00  金庸,武侠,笑傲江湖\n",
      "637251  4507957  1001136     4  2009-07-04T07:55:17+08:00     彼得・潘,童话\n",
      "637252  4507957  1021615     5  2009-07-04T07:53:54+08:00   小王子,童话,经典\n",
      "637253  4507957  1962929     5  2009-06-29T22:13:37+08:00          爱情\n",
      "\n",
      "[637254 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#读取book_score_csv\n",
    "file_path = ('data/book_score.csv')\n",
    "read_data = pd.read_csv(file_path)\n",
    "print(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#用户和书籍的个数，构建矩阵需要\n",
    "users_nums = len(read_data['User'].unique())\n",
    "books_nums = len(read_data['Book'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己的书籍评分数据集类，返回用户 id的index ，书籍 id的index , 以及对应的评分\n",
    "class BookScoreDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, read_data, all_dataset = None):\n",
    "        self.read_data = read_data\n",
    "        if all_dataset == None:\n",
    "            #依据字典索引得到 user 和 book 的 id 列表\n",
    "            self.users_unique_id_list = read_data['User'].unique()\n",
    "            self.books_unique_id_list = read_data['Book'].unique()\n",
    "            self.users_unique_id_list = sorted(set(self.users_unique_id_list))\n",
    "            self.books_unique_id_list = sorted(set(self.books_unique_id_list))\n",
    "            #依据id列表，创建 user 和 book 的分别从 id 到 index 的转换，便于实现利用索引访问对应的矩阵 factor\n",
    "            self.user_id_to_index = {id : index for index, id in enumerate(self.users_unique_id_list)}\n",
    "            self.book_id_to_index = {id : index for index, id in enumerate(self.books_unique_id_list)}\n",
    "        else:\n",
    "            self.user_id_to_index = all_dataset.user_id_to_index\n",
    "            self.book_id_to_index = all_dataset.book_id_to_index\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # 得到数据文件中index对应的一行\n",
    "        one_row = self.read_data.iloc[index]\n",
    "        user_index = self.user_id_to_index[one_row['User']]\n",
    "        book_index = self.book_id_to_index[one_row['Book']]\n",
    "        u_b_rating = one_row['Rate'].astype('float32')\n",
    "        #返回 index\n",
    "        return user_index, book_index, u_b_rating\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#划分数据集，这里我们使用助教样例代码中的train_test_split\n",
    "train_data, test_data = train_test_split(read_data, test_size=0.5, random_state=42)\n",
    "\n",
    "#创建数据集\n",
    "all_dataset = BookScoreDataSet(read_data)\n",
    "train_dataset = BookScoreDataSet(train_data, all_dataset)\n",
    "test_dataset = BookScoreDataSet(test_data, all_dataset)\n",
    "\n",
    "#创建训练和测试数据迭代器，这里批量大小按照助教给出样例中的4096设置\n",
    "batch_size = 512\n",
    "train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础的基于MSE损失的 MF 模型\n",
    "class BaseMSEMFModel(nn.Module):\n",
    "    def __init__(self, factor_dim, users_nums, books_nums):\n",
    "        super(BaseMSEMFModel, self).__init__()\n",
    "        self.user_matrix = nn.Embedding(users_nums, factor_dim)\n",
    "        self.book_matrix = nn.Embedding(books_nums, factor_dim)\n",
    "\n",
    "    # 前向传播函数，得到预测评分值   \n",
    "    def forward(self, X):\n",
    "        user_index, book_index = X\n",
    "        user_vector = self.user_matrix(user_index)\n",
    "        book_vector = self.book_matrix(book_index)\n",
    "        # 经过Embedding层出来的vector形状应该是（batch_size x factor_dim）\n",
    "        # 做点积，得到（batch_size X 1）的预测评分\n",
    "        return (user_vector * book_vector).sum(dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loss, train_iter, batch_size, device, num_epochs = 20, lr = 0.01):\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr = lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for i, X in enumerate(train_iter):\n",
    "            user_index, book_index, u_b_rating = X \n",
    "            # 梯度清零\n",
    "            trainer.zero_grad()\n",
    "            X = (user_index.to(device),book_index.to(device))\n",
    "            # 模型预测\n",
    "            hat_rate = net(X)\n",
    "            # 计算损失\n",
    "            l = loss(hat_rate, u_b_rating.to(device))\n",
    "            train_loss += l.sum()\n",
    "            # 反向传播\n",
    "            l.mean().backward()\n",
    "            # 更新参数\n",
    "            trainer.step()\n",
    "        train_loss = train_loss / ((i + 1) * batch_size)\n",
    "        print(f'At epoch {epoch}, train_loss {train_loss}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0, train_loss 59.39773178100586\n",
      "At epoch 1, train_loss 57.1633186340332\n",
      "At epoch 2, train_loss 55.099525451660156\n",
      "At epoch 3, train_loss 53.17218017578125\n",
      "At epoch 4, train_loss 51.363590240478516\n",
      "At epoch 5, train_loss 49.684539794921875\n",
      "At epoch 6, train_loss 48.10369873046875\n",
      "At epoch 7, train_loss 46.6208381652832\n",
      "At epoch 8, train_loss 45.22600555419922\n",
      "At epoch 9, train_loss 43.90733337402344\n",
      "At epoch 10, train_loss 42.66625213623047\n",
      "At epoch 11, train_loss 41.48992919921875\n",
      "At epoch 12, train_loss 40.384735107421875\n",
      "At epoch 13, train_loss 39.32802200317383\n",
      "At epoch 14, train_loss 38.33295440673828\n",
      "At epoch 15, train_loss 37.38587188720703\n",
      "At epoch 16, train_loss 36.482826232910156\n",
      "At epoch 17, train_loss 35.62949752807617\n",
      "At epoch 18, train_loss 34.81391906738281\n",
      "At epoch 19, train_loss 34.03607177734375\n"
     ]
    }
   ],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BaseMSEMFModel(50, users_nums, books_nums)\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "train(net.to(device), loss, train_iter, batch_size, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
